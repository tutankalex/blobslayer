{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "import json\n",
    "import os\n",
    "import os.path as _p\n",
    "import hashlib\n",
    "from fs.osfs import OSFS\n",
    "from pathlib import Path\n",
    "from schematized_config.core import ConfigValidator\n",
    "from blobslayer.DotenvSchema import DotenvSchema\n",
    "from blobslayer.FileMetadataSchema import FileMetadataSchema\n",
    "from typing import ClassVar\n",
    "import blobslayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def recursive_substitute(env_vars: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Recursively substitute environment variables in the values of the env_vars dictionary.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        changed = False\n",
    "        for key, value in env_vars.items():\n",
    "            substituted_value = value\n",
    "            for k, v in env_vars.items():\n",
    "                # Substitute the value if the key is found in the value string\n",
    "                if f\"${k}\" in substituted_value:\n",
    "                    substituted_value = substituted_value.replace(f\"${k}\", v)\n",
    "                    changed = True\n",
    "            \n",
    "            env_vars[key] = substituted_value\n",
    "\n",
    "        # If no substitutions were made in this pass, break the loop\n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    return env_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "def _load_config(dotenv_path='.env'):\n",
    "    if _p.exists(dotenv_path):\n",
    "        with open(Path(blobslayer.__file__).parent.parent / 'schemas' / 'dotenv.schema.json') as ifile:\n",
    "            json_schema = json.load(ifile)\n",
    "        validated_dotenv = ConfigValidator.load_dotenv(\n",
    "            json_schema=json_schema,\n",
    "            dotenv_path=dotenv_path,\n",
    "            storage_driver=OSFS(os.getcwd()),\n",
    "        )  # use defaults of .env and CONFIG_VALIDATOR_JSON_SCHEMA\n",
    "        return DotenvSchema(**recursive_substitute(validated_dotenv))\n",
    "\n",
    "def _notebook_load_default_config():\n",
    "    config = None\n",
    "    try:\n",
    "        # local block to load .env from project root\n",
    "        cwd = os.getcwd()\n",
    "        os.chdir('..')\n",
    "        config = _load_config()\n",
    "        os.chdir(cwd)\n",
    "    except Exception as e:\n",
    "        print('failed to load env:')\n",
    "        print(e)\n",
    "        os.chdir(cwd)\n",
    "    return config\n",
    "\n",
    "Config = _notebook_load_default_config()\n",
    "assert Config is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def _ensure_storage_directories_exist(config: DotenvSchema):    \n",
    "    Path(config.STORAGE_DIRECTORY).mkdir(parents=True, exist_ok=True)\n",
    "    Path(config.BLOBS_DIRECTORY).mkdir(parents=True, exist_ok=True)\n",
    "    Path(config.METADATA_DIRECTORY).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def sha256sum(data: bytes) -> str:\n",
    "    return hashlib.sha256(data).hexdigest()\n",
    "\n",
    "def to_split_path(hash_path: str) -> str:\n",
    "    return f'{hash_path[:2]}/{hash_path[2:4]}/{hash_path[4:]}'\n",
    "\n",
    "def save_blob(data: bytes, blobs_directory: str=None) -> str:\n",
    "    blobs_directory = blobs_directory or Config.BLOBS_DIRECTORY\n",
    "    assert blobs_directory is not None\n",
    "    blob_key = sha256sum(data)\n",
    "    with OSFS(blobs_directory) as myfs:\n",
    "        blob_path = to_split_path(blob_key)\n",
    "        blob_split_dir, _ = _p.split(blob_path)\n",
    "        myfs.makedirs(blob_split_dir, recreate=True)\n",
    "        if myfs.exists(blob_path):\n",
    "            return blob_key\n",
    "        with myfs.open(blob_path, 'wb') as ofile:\n",
    "            ofile.write(data)\n",
    "    return blob_key\n",
    "\n",
    "def get_blob(blob_key: str, blobs_directory: str=None):  # returns a file-like\n",
    "    blobs_directory = blobs_directory or Config.BLOBS_DIRECTORY\n",
    "    assert blobs_directory is not None\n",
    "    blob_path = to_split_path(blob_key)\n",
    "    with OSFS(blobs_directory) as myfs:\n",
    "        return myfs.open(blob_path, 'rb')\n",
    "\n",
    "def to_metadata_path(filepath: str):\n",
    "    return f'{filepath}.meta.json'\n",
    "\n",
    "def write_file_as_blob(\n",
    "        filepath: str,\n",
    "        data: bytes,\n",
    "        metadata_directory: str=None,\n",
    "        blobs_directory: str=None\n",
    "    ) -> str:\n",
    "    metadata_directory = metadata_directory or Config.METADATA_DIRECTORY\n",
    "    blobs_directory = blobs_directory or Config.BLOBS_DIRECTORY\n",
    "    assert metadata_directory is not None and blobs_directory is not None\n",
    "    blob_key = save_blob(data, blobs_directory)\n",
    "    file_metadata = FileMetadataSchema(\n",
    "        blobKey = blob_key,\n",
    "    )\n",
    "    with OSFS(metadata_directory) as myfs:\n",
    "        metadata_path = to_metadata_path(filepath)\n",
    "        metadata_sub_dir, _ = _p.split(metadata_path)\n",
    "        myfs.makedirs(metadata_sub_dir, recreate=True)\n",
    "        with myfs.open(metadata_path, 'w') as ofile:\n",
    "            ofile.write(json.dumps(dict(file_metadata)))\n",
    "    return blob_key\n",
    "\n",
    "def get_file_metadata(\n",
    "        filepath: str,\n",
    "        metadata_directory: str=None,\n",
    ") -> dict:\n",
    "    metadata_directory = metadata_directory or Config.METADATA_DIRECTORY\n",
    "    assert metadata_directory is not None\n",
    "    with OSFS(metadata_directory) as myfs:\n",
    "        metadata_path = to_metadata_path(filepath)\n",
    "        if not myfs.exists(metadata_path):\n",
    "            return None\n",
    "        with myfs.open(metadata_path) as ifile:\n",
    "            return json.load(ifile)\n",
    "        \n",
    "def set_file_metadata(\n",
    "        filepath: str,\n",
    "        metadata,\n",
    "        metadata_directory: str=None,\n",
    "):\n",
    "    metadata_directory = metadata_directory or Config.METADATA_DIRECTORY\n",
    "    assert metadata_directory is not None\n",
    "    with OSFS(metadata_directory) as myfs:\n",
    "        metadata_path = to_metadata_path(filepath)\n",
    "        with myfs.open(metadata_path, 'w') as ofile:\n",
    "            ofile.write(json.dumps(dict(metadata)))\n",
    "\n",
    "def read_file_blob(\n",
    "        filepath: str,\n",
    "        metadata_directory: str=None,\n",
    "        blobs_directory: str=None\n",
    "    ):\n",
    "    metadata_directory = metadata_directory or Config.METADATA_DIRECTORY\n",
    "    blobs_directory = blobs_directory or Config.BLOBS_DIRECTORY\n",
    "    assert metadata_directory is not None and blobs_directory is not None\n",
    "    metadata = get_file_metadata(filepath, metadata_directory)\n",
    "    assert metadata is not None\n",
    "    file_metadata = FileMetadataSchema(**metadata)\n",
    "    return get_blob(file_metadata.blobKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BlobSlayer(DotenvSchema):\n",
    "\n",
    "    _default_instance: ClassVar['BlobSlayer'] = None\n",
    "    \n",
    "    @classmethod\n",
    "    def get_default_instance(cls, default_conf: DotenvSchema=None):\n",
    "        if cls._default_instance is None:\n",
    "            default_conf = default_conf or cls()\n",
    "            cls._default_instance = cls(**recursive_substitute(dict(default_conf)))\n",
    "            _ensure_storage_directories_exist(cls._default_instance)\n",
    "        return cls._default_instance\n",
    "    \n",
    "    def get_metadata(self, filepath: str) -> dict:\n",
    "        return get_file_metadata(\n",
    "            filepath,\n",
    "            self.METADATA_DIRECTORY)\n",
    "\n",
    "    def set_metadata(self, filepath: str, metadata):\n",
    "        return set_file_metadata(\n",
    "            filepath,\n",
    "            metadata,\n",
    "            self.METADATA_DIRECTORY)\n",
    "\n",
    "    def save_file(self, filepath: str, data: bytes):\n",
    "        return write_file_as_blob(\n",
    "            filepath,\n",
    "            data,\n",
    "            metadata_directory=self.METADATA_DIRECTORY,\n",
    "            blobs_directory=self.BLOBS_DIRECTORY)\n",
    "    \n",
    "    def load_file(self, filepath: str):\n",
    "        return read_file_blob(\n",
    "            filepath,\n",
    "            metadata_directory=self.METADATA_DIRECTORY,\n",
    "            blobs_directory=self.BLOBS_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "bs = BlobSlayer.get_default_instance(_notebook_load_default_config())\n",
    "\n",
    "file_path = 'foo/bar/baz.txt'\n",
    "file_content = b'lorem ipsum'\n",
    "my_file = bs.save_file(file_path, file_content)\n",
    "with (bs.load_file(file_path)) as ifile:\n",
    "    test_eq(ifile.read(), file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
